.create-or-alter function EvaluationFlowInsert() {
     let AppTracesTbl = 
        traces_table
        | extend item = parse_json(records)
        | mv-expand item
        | serialize
        | extend RowNumber = row_number(1, prev(PartitionId) != PartitionId) 
        | where item.Type == "AppTraces" 
        | project
            EventProcessedUtcTime,
            PartitionId,
            RowNumber,
            item,
            metricName = item.metricName,
            Target = item.Target,
            Type = item.Type,
            PropertiesPayload = dynamic_to_json(item.Properties.payload);
     AppTracesTbl
    | project
        item_time = todatetime((item)["time"]),
        toguid(item.OperationId),
        tostring(item.ParentId),
        Message = dynamic_to_json(item.Message)
    | where Message has "batch-evaluation-flow-metrics"
    | extend parsed_json = parse_json(Message)
    | extend 
        AgentName = tostring(parsed_json.metadata.tags.run_configuraton.AgentConfiguration.agent_name),		
        ConfigVersion = tostring(parsed_json.metadata.tags.run_configuraton.AgentConfiguration.config_version),
        ModelName = tostring(parsed_json.metadata.tags.run_configuraton.AgentConfiguration.model_name),
        ModelVersion = tostring(parsed_json.metadata.tags.run_configuraton.AgentConfiguration.model_version),
        ModelDeploymentName = tostring(parsed_json.metadata.tags.run_configuraton.AgentConfiguration.model_deployment),
        OpenAIAPIVersion = tostring(parsed_json.metadata.tags.run_configuraton.AgentConfiguration.openai_api_version),
        IntentSystemPrompt = tostring(parsed_json.metadata.tags.run_configuraton.AgentConfiguration.intent_system_prompt),
        ChatSystemPrompt = tostring(parsed_json.metadata.tags.run_configuraton.AgentConfiguration.chat_system_prompt),
        Deployment = tostring(parsed_json.metadata.tags.run_configuraton.AgentConfiguration.model_deployment_endpoint),
        Temperature = tostring(parsed_json.metadata.tags.run_configuraton.AgentConfiguration.model_parameters.temperature),
        Seed = tolong(parsed_json.metadata.tags.run_configuraton.AgentConfiguration.model_parameters.seed),
        EmbeddingEndpoint = tostring(parsed_json.metadata.tags.run_configuraton.AgentConfiguration.retrieval.embedding_endpoint),
        EmbeddingDeployment = tostring(parsed_json.metadata.tags.run_configuraton.AgentConfiguration.retrieval.embedding_deployment),
        SearchType = tostring(parsed_json.metadata.tags.run_configuraton.AgentConfiguration.retrieval.search_type),
        SearchTopK = tolong(parsed_json.metadata.tags.run_configuraton.AgentConfiguration.retrieval.top_k),
        TotalTokens = tolong(parsed_json.metadata.properties.system_metrics.total_tokens),
        PromptTokens = tolong(parsed_json.metadata.properties.system_metrics.prompt_tokens),
        CompletionTokens = tolong(parsed_json.metadata.properties.system_metrics.completion_tokens),
        Duration = tolong(parsed_json.metadata.properties.system_metrics.duration)       
    | where isnotempty(AgentName)         
    | mv-expand result = parsed_json.result
    | extend metric = tostring(result.metric), score = toreal(result.score)
    | project-away Message, parsed_json, result
    | evaluate pivot(metric, any(score))
    | sort by item_time asc
    | project
        EventTime = item_time,
        item_OperationId,
        item_ParentId,
        AgentName,
        ConfigVersion,
        ModelName,
        ModelVersion,
        ModelDeploymentName,
        OpenAIAPIVersion,
        Deployment,
        TotalTokens,
        PromptTokens,
        CompletionTokens,
        Duration,
        Temperature,
        Seed,
        EmbeddingEndpoint,
        EmbeddingDeployment,
        SearchType,
        SearchTopK,
        IntentSystemPrompt,
        ChatSystemPrompt,
        Coherence = coherence,
        Groundedness = groundedness,
        Relevance = relevance,
        Similarity = similarity
 }
    
   .create table 
    Evaluation (EventTime: datetime, item_OperationId: guid, item_ParentId: string, AgentName: string, ConfigVersion: string, ModelName: string, ModelVersion: string, ModelDeploymentName: string, OpenAIAPIVersion: string,
    Deployment: string, TotalTokens: long, PromptTokens: long, CompletionTokens: long, Duration: long, Temperature: string, Seed: long, EmbeddingEndpoint:string, EmbeddingDeployment: string, SearchType: string, SearchTopK: long, IntentSystemPrompt: string, ChatSystemPrompt: string,
    Coherence: real, Groundedness: real, Relevance: real, Similarity: real)

//.drop table EvaluationFlow

.alter table Evaluation policy update
    @'[{ "IsEnabled": true, "Source": "traces_table", "Query": "EvaluationFlowInsert()", "IsTransactional": true}]'

.set-or-append Evaluation <|
    EvaluationFlowInsert()


